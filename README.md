# üìò Books Streamer - Raspagem de Livros

Este projeto consiste em um script Python que realiza web scraping do site "books.toscrape.com" para coletar informa√ß√µes sobre livros. Os dados coletados s√£o exibidos em uma interface web interativa criada com Streamlit, permitindo ao usu√°rio pesquisar, ordenar e baixar os dados em formato CSV.

## Funcionalidades

*   Raspagem de todos os livros listados no site (aproximadamente 1.000 livros).
*   Extra√ß√£o de detalhes como t√≠tulo, avalia√ß√£o (estrelas), pre√ßo, UPC, disponibilidade, etc.
*   Interface web para visualiza√ß√£o dos dados.
*   Pesquisa de livros por t√≠tulo.
*   Ordena√ß√£o dos livros por nome, avalia√ß√£o ou pre√ßo.
*   Download dos dados coletados em um arquivo CSV.

## Pr√©-requisitos

*   Python 3.7+

## Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio (ou baixe os arquivos):**
    ```bash
    # Se estiver usando Git
    git clone <url-do-repositorio>
    cd <nome-do-repositorio>
    ```

2.  **Crie e ative um ambiente virtual (recomendado):**
    ```bash
    python -m venv venv
    ```
    *   No Windows:
        ```bash
        venv\\Scripts\\activate
        ```
    *   No macOS/Linux:
        ```bash
        source venv/bin/activate
        ```

3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

## Como Executar

Ap√≥s a configura√ß√£o do ambiente e instala√ß√£o das depend√™ncias, execute o script Streamlit:

```bash
streamlit run main.py
```

Isso dever√° abrir a aplica√ß√£o no seu navegador padr√£o.

## Estrutura do C√≥digo

*   `main.py`: Script principal contendo a l√≥gica de raspagem, as fun√ß√µes de processamento de dados e a interface Streamlit.
*   `requirements.txt`: Lista das bibliotecas Python necess√°rias para o projeto.
*   `.gitignore`: Especifica arquivos e pastas a serem ignorados pelo Git.
*   `README.md`: Este arquivo, fornecendo informa√ß√µes sobre o projeto.

## Bibliotecas Utilizadas

*   [Streamlit](https://streamlit.io/): Para a cria√ß√£o da interface web interativa.
*   [Requests](https://requests.readthedocs.io/): Para realizar requisi√ß√µes HTTP.
*   [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Para fazer o parsing do HTML.
*   [Pandas](https://pandas.pydata.org/): Para manipula√ß√£o e estrutura√ß√£o dos dados.
