# üìò Books Streamer - Raspagem de Livros

Este projeto consiste em um script Python que realiza web scraping do site "books.toscrape.com" para coletar informa√ß√µes sobre livros. Os dados coletados s√£o exibidos em uma interface web interativa criada com Streamlit, permitindo ao usu√°rio pesquisar, ordenar e baixar os dados em formato CSV.

## Funcionalidades

*   Raspagem de todos os livros listados no site (aproximadamente 1.000 livros).
*   Extra√ß√£o de detalhes como t√≠tulo, avalia√ß√£o (estrelas), pre√ßo, UPC, disponibilidade, etc.
*   Interface web para visualiza√ß√£o dos dados.
*   Pesquisa de livros por t√≠tulo.
*   Ordena√ß√£o dos livros por nome, avalia√ß√£o ou pre√ßo.
*   Download dos dados coletados em um arquivo CSV.

## Pr√©-requisitos

*   Python 3.7+

## Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio (ou baixe os arquivos):**
    ```bash
    # Se estiver usando Git
    git clone <url-do-repositorio>
    cd <nome-do-repositorio>
    ```

2.  **Crie e ative um ambiente virtual (recomendado):**
    ```bash
    python -m venv venv
    ```
    *   No Windows:
        ```bash
        venv\\Scripts\\activate
        ```
    *   No macOS/Linux:
        ```bash
        source venv/bin/activate
        ```

3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

## Como Executar

Ap√≥s a configura√ß√£o do ambiente e instala√ß√£o das depend√™ncias, execute o script Streamlit:

```bash
streamlit run main.py
```

Isso dever√° abrir a aplica√ß√£o no seu navegador padr√£o.

## Estrutura do C√≥digo

*   `main.py`: Script principal contendo a l√≥gica de raspagem, as fun√ß√µes de processamento de dados e a interface Streamlit.
*   `requirements.txt`: Lista das bibliotecas Python necess√°rias para o projeto.
*   `.gitignore`: Especifica arquivos e pastas a serem ignorados pelo Git.
*   `README.md`: Este arquivo, fornecendo informa√ß√µes sobre o projeto.

## Bibliotecas Utilizadas

*   [Streamlit](https://streamlit.io/): Para a cria√ß√£o da interface web interativa.
*   [Requests](https://requests.readthedocs.io/): Para realizar requisi√ß√µes HTTP.
*   [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Para fazer o parsing do HTML.
*   [Pandas](https://pandas.pydata.org/): Para manipula√ß√£o e estrutura√ß√£o dos dados.

## Detalhes da Sa√≠da (CSV)

Os dados coletados podem ser baixados como um arquivo CSV (`books_all_pages.csv`). Este arquivo possui as seguintes caracter√≠sticas:
*   **Delimitador:** Ponto e v√≠rgula (`;`)
*   **Encoding:** UTF-8 com BOM (Byte Order Mark), o que geralmente garante boa compatibilidade com softwares como Microsoft Excel.
*   **Principais Colunas:** `name`, `rate` (avalia√ß√£o textual), `value` (pre√ßo com s√≠mbolo da moeda), `url` (link direto para a p√°gina do livro), `upc`, `product type`, `price (excl. tax)`, `price (incl. tax)`, `tax`, `availability`, `number of reviews`.

## Solu√ß√£o de Problemas (Troubleshooting)

*   **Falha na Raspagem:**
    *   Verifique sua conex√£o com a internet.
    *   O site `books.toscrape.com` pode estar temporariamente indispon√≠vel. Tente novamente mais tarde.
    *   Em cen√°rios de scraping mais intensos (n√£o aplic√°vel aqui), o IP poderia ser bloqueado.
*   **Caracteres Estranhos no CSV:**
    *   O arquivo CSV √© gerado em UTF-8. Certifique-se de que o software que voc√™ est√° usando para abrir o CSV est√° interpretando este encoding corretamente. A inclus√£o do BOM visa ajudar nisso.
*   **Erro ao executar `streamlit run main.py`:**
    *   Certifique-se de que voc√™ ativou o ambiente virtual (`venv`) e instalou todas as depend√™ncias listadas em `requirements.txt`.

## Licen√ßa

Este projeto √© distribu√≠do sob os termos da Licen√ßa MIT. Veja o arquivo `LICENSE.md` para mais detalhes.
